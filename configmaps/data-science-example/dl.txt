n_layers=3
activation=relu
dropout=0.5
optimizer=adam
batch_size=64
warmup_steps=4000
